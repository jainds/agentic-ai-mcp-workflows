name: 🚀 CI/CD Pipeline

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production
      force_deploy:
        description: 'Force deployment even if tests fail'
        required: false
        default: false
        type: boolean
      skip_tests:
        description: 'Skip test execution'
        required: false
        default: false
        type: boolean

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build-and-test:
    name: 🏗️ Build & Test
    runs-on: ubuntu-latest
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}
      test-results: ${{ steps.test.outputs.results }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'
          cache: 'pip'
      
      - name: 🏷️ Extract metadata for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
            type=raw,value={{date 'YYYYMMDD-HHmmss'}}

      - name: 🧪 Run comprehensive tests
        id: test
        if: ${{ !github.event.inputs.skip_tests }}
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-json-report
          
          echo "Running unit tests..."
          python -m pytest tests/unit/ -v \
            --cov=. --cov-report=xml --cov-report=term \
            --json-report --json-report-file=unit-test-results.json || true
          
          echo "Running integration tests..."
          python -m pytest tests/integration/ -v \
            --json-report --json-report-file=integration-test-results.json || true
          
          # Extract test summary
          if [ -f unit-test-results.json ]; then
            unit_tests=$(cat unit-test-results.json | jq -r '.summary.total // 0')
            unit_passed=$(cat unit-test-results.json | jq -r '.summary.passed // 0')
            echo "results=Unit: $unit_passed/$unit_tests passed" >> $GITHUB_OUTPUT
          fi
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: 🐳 Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64
      
      - name: Upload test artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results
          path: |
            unit-test-results.json
            integration-test-results.json
            coverage.xml

  deploy-staging:
    name: 🚀 Deploy to Staging
    needs: build-and-test
    runs-on: ubuntu-latest
    environment: staging
    if: github.ref == 'refs/heads/main' || github.event.inputs.environment == 'staging'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'
      
      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: '3.13.0'
      
      - name: 🔧 Configure kubectl for staging
        run: |
          echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > $HOME/.kube/config
          kubectl config use-context default || true
          kubectl create namespace insurance-ai-staging --dry-run=client -o yaml | kubectl apply -f -
      
      - name: 📊 Deploy to staging with Helm
        run: |
          # Extract the first tag from the metadata
          IMAGE_TAG=$(echo "${{ needs.build-and-test.outputs.image-tag }}" | cut -d',' -f1)
          
          helm upgrade --install insurance-ai-poc ./k8s/insurance-ai-poc \
            --namespace insurance-ai-staging \
            --create-namespace \
            --set image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} \
            --set image.tag=${IMAGE_TAG##*:} \
            --set environment=staging \
            --set replicaCount=1 \
            --set resources.requests.cpu=200m \
            --set resources.requests.memory=512Mi \
            --set resources.limits.cpu=1000m \
            --set resources.limits.memory=2Gi \
            --set secrets.openrouterApiKey="${{ secrets.OPENROUTER_API_KEY }}" \
            --set secrets.openaiApiKey="${{ secrets.OPENAI_API_KEY }}" \
            --set secrets.langfuseSecretKey="${{ secrets.LANGFUSE_SECRET_KEY }}" \
            --set secrets.langfusePublicKey="${{ secrets.LANGFUSE_PUBLIC_KEY }}" \
            --wait --timeout=10m
      
      - name: ⏳ Wait for deployment to be ready
        run: |
          kubectl wait --for=condition=available deployment \
            -l app.kubernetes.io/instance=insurance-ai-poc \
            --timeout=300s \
            -n insurance-ai-staging
      
      - name: 🔍 Get deployment status
        run: |
          kubectl get pods -n insurance-ai-staging
          kubectl get services -n insurance-ai-staging

  e2e-tests:
    name: 🎯 E2E Tests
    needs: [build-and-test, deploy-staging]
    runs-on: ubuntu-latest
    if: needs.deploy-staging.result == 'success'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'
          cache: 'pip'
      
      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'
      
      - name: 🔧 Configure kubectl
        run: |
          echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > $HOME/.kube/config
      
      - name: 🌐 Set up port forwarding for E2E tests
        run: |
          # Start port forwarding in background
          kubectl port-forward -n insurance-ai-staging service/insurance-ai-poc-policy-server 8001:8001 &
          kubectl port-forward -n insurance-ai-staging service/insurance-ai-poc-technical-agent 8002:8002 &
          kubectl port-forward -n insurance-ai-staging service/insurance-ai-poc-domain-agent 8003:8003 &
          kubectl port-forward -n insurance-ai-staging service/insurance-ai-poc-streamlit 8501:8501 &
          
          # Wait for port forwards to be ready
          sleep 30
      
      - name: 🧪 Run E2E tests
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-json-report
          
          # Run E2E tests with staging endpoints
          python -m pytest tests/e2e/ -v \
            --json-report --json-report-file=e2e-test-results.json \
            -k "not requires_production" || true
        env:
          POLICY_SERVER_URL: http://localhost:8001
          TECHNICAL_AGENT_URL: http://localhost:8002
          DOMAIN_AGENT_URL: http://localhost:8003
          STREAMLIT_URL: http://localhost:8501
      
      - name: Upload E2E test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-test-results
          path: e2e-test-results.json

  deploy-production:
    name: 🚀 Production Deployment
    needs: [build-and-test, e2e-tests]
    runs-on: ubuntu-latest
    environment: production
    if: |
      (needs.e2e-tests.result == 'success' || github.event.inputs.force_deploy == 'true') &&
      (github.ref == 'refs/heads/main' || github.event.inputs.environment == 'production')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'
      
      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: '3.13.0'
      
      - name: 🔧 Configure kubectl for production
        run: |
          echo "${{ secrets.KUBE_CONFIG_PRODUCTION }}" | base64 -d > $HOME/.kube/config
          kubectl config use-context default || true
          kubectl create namespace insurance-ai-production --dry-run=client -o yaml | kubectl apply -f -
      
      - name: 📊 Deploy to production with Helm
        run: |
          # Extract the first tag from the metadata
          IMAGE_TAG=$(echo "${{ needs.build-and-test.outputs.image-tag }}" | cut -d',' -f1)
          
          helm upgrade --install insurance-ai-poc ./k8s/insurance-ai-poc \
            --namespace insurance-ai-production \
            --create-namespace \
            --set image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} \
            --set image.tag=${IMAGE_TAG##*:} \
            --set environment=production \
            --set replicaCount=2 \
            --set resources.requests.cpu=500m \
            --set resources.requests.memory=1Gi \
            --set resources.limits.cpu=2000m \
            --set resources.limits.memory=4Gi \
            --set autoscaling.enabled=true \
            --set autoscaling.minReplicas=2 \
            --set autoscaling.maxReplicas=10 \
            --set autoscaling.targetCPUUtilizationPercentage=70 \
            --set secrets.openrouterApiKey="${{ secrets.OPENROUTER_API_KEY }}" \
            --set secrets.openaiApiKey="${{ secrets.OPENAI_API_KEY }}" \
            --set secrets.langfuseSecretKey="${{ secrets.LANGFUSE_SECRET_KEY }}" \
            --set secrets.langfusePublicKey="${{ secrets.LANGFUSE_PUBLIC_KEY }}" \
            --wait --timeout=15m
      
      - name: ⏳ Wait for production deployment
        run: |
          kubectl wait --for=condition=available deployment \
            -l app.kubernetes.io/instance=insurance-ai-poc \
            --timeout=600s \
            -n insurance-ai-production
      
      - name: 🔍 Verify production deployment
        run: |
          kubectl get pods -n insurance-ai-production
          kubectl get services -n insurance-ai-production
          kubectl get hpa -n insurance-ai-production

  notify:
    name: 📢 Notify Team
    needs: [build-and-test, deploy-staging, e2e-tests, deploy-production]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Create deployment summary
        id: summary
        run: |
          if [[ "${{ needs.deploy-production.result }}" == "success" ]]; then
            STATUS="🎉 Production deployment successful!"
            COLOR="good"
          elif [[ "${{ needs.deploy-staging.result }}" == "success" ]]; then
            STATUS="✅ Staging deployment successful"
            COLOR="warning"
          else
            STATUS="❌ Deployment failed"
            COLOR="danger"
          fi
          
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          echo "color=$COLOR" >> $GITHUB_OUTPUT
      
      - name: Slack notification
        if: ${{ secrets.SLACK_WEBHOOK_URL }}
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ steps.summary.outputs.color }}
          fields: repo,message,commit,author,action,eventName,ref,workflow
          text: |
            ${{ steps.summary.outputs.status }}
            
            **Build:** ${{ needs.build-and-test.result }}
            **Tests:** ${{ needs.build-and-test.outputs.test-results }}
            **Staging:** ${{ needs.deploy-staging.result }}
            **E2E Tests:** ${{ needs.e2e-tests.result }}
            **Production:** ${{ needs.deploy-production.result }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }} 