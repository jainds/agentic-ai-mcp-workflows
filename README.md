# ğŸ¤– Insurance AI Multi-Agent System

A sophisticated multi-agent AI system for insurance operations, featuring comprehensive observability and monitoring capabilities.

## ğŸŒŸ **Features**

### **ğŸ¤– Multi-Agent Architecture**
- **Domain Agents**: Orchestrate business workflows (Claims, Support)
- **Technical Agents**: Handle data operations (Customer, Policy, Claims Data)
- **LLM Integration**: Advanced intent detection and response generation
- **A2A Protocol**: Seamless agent-to-agent communication

### **ğŸ” Comprehensive Observability**
- **ğŸ“Š Distributed Tracing** with Jaeger - Track requests across agents
- **ğŸ“ˆ Metrics Collection** with Prometheus - Monitor performance and usage
- **ğŸ“Š Visual Dashboards** with Grafana - Real-time system insights
- **ğŸ§  LLM Observability** with LangFuse - Track AI performance and costs
- **ğŸš¨ Alerting & Monitoring** - Proactive issue detection

### **ğŸ¯ Supported Workflows**
- **Claim Status Inquiries** - Check existing claim status
- **Claim Filing Assistance** - Guide new claim submissions
- **General Customer Support** - Handle various customer questions

## ğŸš€ **Quick Start**

### **1. Prerequisites**
```bash
# Kubernetes cluster (Docker Desktop, minikube, etc.)
kubectl version

# Required tools
python 3.8+
docker
```

### **2. Deploy the System**
```bash
# Clone repository
git clone <repo-url>
cd agentic-ai-mcp-workflows

# Deploy insurance agents
cd scripts
./deploy_all.sh

# Deploy observability stack  
./deploy_observability.sh
```

### **3. Access Points**

#### **ğŸ’¬ Chat Interface**
```bash
# Main application
http://localhost:30008
```

#### **ğŸ“Š Monitoring Dashboards**
```bash
# Grafana - Visual dashboards
http://localhost:30030 (admin/admin123)

# Prometheus - Metrics & alerts
http://localhost:30090

# Jaeger - Distributed tracing  
http://localhost:30016
```

### **4. Test the System**
```bash
# Test claim inquiry
curl -X POST "http://localhost:30008/execute" \
  -H "Content-Type: application/json" \
  -d '{"skill_name": "HandleClaimInquiry", "parameters": {"user_message": "What is my claim status? my claimid is 1002, customer id is 101"}}'
```

## ğŸ“Š **Observability Overview**

### **ğŸ” Multi-Layer Monitoring**

```mermaid
graph TB
    A[User Request] --> B[Claims Agent]
    B --> C[LLM Intent Detection]
    B --> D[Claims Data Agent]
    B --> E[LLM Response Generation]
    
    C --> F[ğŸ” Jaeger Traces]
    D --> F
    E --> F
    
    B --> G[ğŸ“ˆ Prometheus Metrics]
    C --> G
    D --> G
    E --> G
    
    F --> H[ğŸ“Š Grafana Dashboards]
    G --> H
    
    C --> I[ğŸ§  LangFuse LLM Tracking]
    E --> I
```

### **ğŸ“ˆ Key Metrics Monitored**

#### **ğŸš€ Performance**
- Agent response time (95th percentile)
- Workflow success rates
- LLM latency and token usage
- Error rates by component

#### **ğŸ’° Cost & Usage**
- LLM token consumption by model
- Cost per claim processed
- Daily API usage trends
- Resource utilization

#### **ğŸ”§ Operational**
- Agent health status
- Inter-agent communication latency
- System resource usage
- Request volume patterns

## ğŸ—ï¸ **System Architecture**

### **ğŸ¤– Agent Types**

#### **Domain Agents** (Business Logic)
```
ğŸ“‹ Claims Domain Agent (Port 8008)
â”œâ”€â”€ Skill: HandleClaimInquiry
â”œâ”€â”€ Skill: HandleClaimFiling  
â””â”€â”€ Integrates: LLM + Technical Agents

ğŸ§ Support Domain Agent (Port 8009)
â”œâ”€â”€ Skill: HandleGeneralSupport
â””â”€â”€ Provides: Customer assistance
```

#### **Technical Agents** (Data Operations)
```
ğŸ‘¤ Customer Agent (Port 8010)
â”œâ”€â”€ Skill: GetCustomerInfo
â””â”€â”€ Data: Customer profiles

ğŸ“„ Policy Agent (Port 8011) 
â”œâ”€â”€ Skill: GetPolicyInfo
â””â”€â”€ Data: Insurance policies

ğŸ“Š Claims Data Agent (Port 8012)
â”œâ”€â”€ Skill: GetClaimStatus
â”œâ”€â”€ Skill: CreateClaim
â””â”€â”€ Data: Claims database
```

### **ğŸ§  LLM Integration**
- **Intent Detection**: Classify user requests
- **ID Extraction**: Parse claim/customer IDs from natural language
- **Response Generation**: Create professional customer responses
- **Model**: OpenAI GPT-4o-mini (optimized for speed + cost)

## ğŸ“‹ **Workflow Examples**

### **ğŸ” Claim Status Inquiry**
```
1. User: "What is my claim status? claimid is 1002"
2. Claims Agent: Receives request
3. LLM: Extracts intent="claim_status", claim_id=1002
4. Claims Data Agent: Fetches claim status
5. LLM: Generates professional response
6. Response: "Your claim 1002 is approved for $9,500"

ğŸ“Š Observability: Full trace in Jaeger, metrics in Prometheus
```

### **ğŸ“ New Claim Filing**
```
1. User: "I need to file a car accident claim"
2. Claims Agent: Detects intent="claim_filing"
3. LLM: Extracts incident details
4. Claims Data Agent: Creates new claim
5. Response: Claim confirmation + next steps

ğŸ“Š Observability: Track filing success rates, processing time
```

## ğŸ”§ **Development**

### **ğŸ› ï¸ Local Setup**
```bash
# Install dependencies
pip install -r requirements.txt

# Set environment variables
cp .env.example .env
# Edit .env with your API keys

# Run tests
python -m pytest tests/ -v

# Run individual agents
python agents/domain/claims_domain_agent.py
```

### **ğŸ§ª Testing**
```bash
# Integration tests
python tests/run_integration_tests.py

# Deployment verification
python scripts/verify_deployment.py

# Observability tests
python tests/test_observability.py
```

### **ğŸ“Š Monitoring Development**
```bash
# Generate test metrics
python scripts/generate_test_traffic.py

# View traces in Jaeger
open http://localhost:30016

# Check metrics in Prometheus
open http://localhost:30090

# Monitor dashboards in Grafana
open http://localhost:30030
```

## ğŸ“š **Documentation**

- **[ğŸ“Š Observability Guide](docs/OBSERVABILITY_GUIDE.md)** - Complete monitoring setup
- **[ğŸš€ Deployment Summary](DEPLOYMENT_SUMMARY.md)** - Quick reference
- **[ğŸ§ª Testing Guide](tests/README.md)** - Test strategies

## ğŸ¯ **Key Capabilities**

### **âœ… Production Ready**
- Comprehensive error handling
- Health checks and monitoring
- Kubernetes deployment
- Horizontal scaling support

### **ğŸ” Full Observability**
- Request tracing across all agents
- LLM usage and cost tracking
- Performance metrics and alerting
- Business intelligence dashboards

### **ğŸ§  AI-Powered**
- Advanced intent detection
- Natural language processing
- Context-aware responses
- Multi-model LLM support

### **ğŸš€ High Performance**
- 7-second average response time
- Async agent communication
- Optimized LLM models
- Intelligent caching

## ğŸŒŸ **Recent Improvements**

### **ğŸ” Observability Stack**
- **Added**: Complete monitoring with Jaeger, Prometheus, Grafana
- **Added**: LangFuse integration for LLM observability
- **Added**: Custom metrics for agent performance
- **Added**: Pre-built dashboards for business insights

### **ğŸ¯ Enhanced Performance**
- **Improved**: Response time from 40s â†’ 7s
- **Optimized**: LLM model selection (GPT-4o-mini)
- **Enhanced**: Error handling and recovery
- **Added**: Comprehensive test coverage

### **ğŸ› ï¸ Developer Experience**
- **Added**: Deployment verification scripts
- **Enhanced**: Local development setup
- **Improved**: Documentation and guides
- **Added**: Integration test framework

## ğŸ¤ **Contributing**

1. **Fork the repository**
2. **Create feature branch** (`git checkout -b feature/amazing-feature`)
3. **Run tests** (`python -m pytest`)
4. **Commit changes** (`git commit -m 'Add amazing feature'`)
5. **Push to branch** (`git push origin feature/amazing-feature`)
6. **Open Pull Request**

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

**ğŸ‰ Built with â¤ï¸ for the future of insurance AI!**