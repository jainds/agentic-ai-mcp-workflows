# ğŸ” Comprehensive Observability Guide
## Multi-Agent Insurance AI System Monitoring

### ğŸ¯ **Observability Strategy Overview**

Our multi-layer observability approach provides complete visibility into:
- **ğŸ¤– Agent Interactions** - Inter-agent communication and workflows
- **ğŸ§  LLM Performance** - Token usage, latency, costs, prompt effectiveness  
- **ğŸ“Š System Health** - Infrastructure metrics, errors, performance
- **ğŸ”„ Business Metrics** - Claim processing success rates, customer satisfaction

---

## ğŸ› ï¸ **Quick Setup**

### **1. Deploy Observability Stack**
```bash
cd scripts
./deploy_observability.sh
```

### **2. Access Dashboards**
- **ğŸ“Š Grafana**: http://localhost:30030 (admin/admin123)
- **ğŸ“ˆ Prometheus**: http://localhost:30090 
- **ğŸ” Jaeger**: http://localhost:30016

---

## ğŸ“Š **Monitoring Components**

### **ğŸ” Jaeger - Distributed Tracing**

**Purpose**: Track requests across multiple agents
**Use Cases**:
- Debug slow claim processing workflows
- Identify bottlenecks in multi-agent conversations
- Trace errors through the system

**Key Features**:
```
ğŸŒ Request Flow Visualization
â±ï¸  End-to-end Latency Analysis  
âŒ Error Propagation Tracking
ğŸ”— Agent Communication Chains
```

**Example Traces**:
- `ClaimsDomainAgent` â†’ `ClaimsDataAgent.GetClaimStatus`
- `HandleClaimInquiry` â†’ Intent Detection â†’ ID Extraction â†’ Response Generation

### **ğŸ“ˆ Prometheus - Metrics Collection**

**Purpose**: Collect and query time-series metrics
**Use Cases**:
- Monitor agent performance trends
- Track LLM usage and costs
- Set up alerts for system issues

**Key Metrics**:
```yaml
# Agent Communication
agent_requests_total{source_agent, target_agent, skill_name, status}
agent_request_duration_seconds{source_agent, target_agent, skill_name}

# LLM Usage  
llm_requests_total{model, task_type, status}
llm_request_duration_seconds{model, task_type}
llm_tokens_total{model, task_type, token_type}

# Workflow Performance
workflow_executions_total{workflow_type, status}
workflow_duration_seconds{workflow_type}

# System Health
agent_health_status{agent_name}
active_sessions_total
```

### **ğŸ“Š Grafana - Visual Dashboards**

**Purpose**: Beautiful, interactive dashboards
**Use Cases**:
- Real-time monitoring of agent performance
- Historical analysis of system usage
- Business intelligence on claim processing

**Pre-built Dashboards**:
- **Insurance Agent Overview** - System health at a glance
- **LLM Performance** - Token usage, costs, model comparison
- **Workflow Analysis** - Success rates, processing times
- **Error Tracking** - Failed requests, error patterns

---

## ğŸ§  **LLM Observability with LangFuse** 

### **Setup (Optional but Recommended)**
1. **Sign up**: https://cloud.langfuse.com
2. **Get API keys** from your LangFuse dashboard
3. **Add to Kubernetes**:
```bash
kubectl create secret generic langfuse-keys -n insurance-poc \
  --from-literal=LANGFUSE_PUBLIC_KEY="pk-..." \
  --from-literal=LANGFUSE_SECRET_KEY="sk-..."
```

### **LangFuse Capabilities**
```
ğŸ“ Prompt Engineering Analysis
ğŸ’° Cost Tracking by Model
ğŸ¯ A/B Testing Different Prompts  
ğŸ”„ Conversation Flow Analysis
ğŸ“Š Token Usage Optimization
âš¡ Performance Benchmarking
```

### **Example LangFuse Traces**
- **Intent Detection**: User message â†’ LLM call â†’ Extracted intent
- **Response Generation**: Context + Data â†’ LLM call â†’ Customer response
- **ID Extraction**: Natural language â†’ Structured IDs

---

## ğŸ¯ **Key Metrics to Monitor**

### **ğŸš€ Performance Metrics**
```
ğŸ“Š Agent Response Time (95th percentile)
Target: < 5 seconds for claim status

ğŸ”„ Workflow Success Rate  
Target: > 95% for claim inquiries

âš¡ LLM Response Time
Target: < 3 seconds per call

ğŸ¯ Intent Detection Accuracy
Target: > 90% correct classification
```

### **ğŸ’° Cost Metrics**
```
ğŸ’µ LLM Token Usage per Day
ğŸ“ˆ Cost per Claim Processed
ğŸ“Š Token Efficiency by Model
ğŸ¯ Cost per Customer Interaction
```

### **ğŸ”§ Operational Metrics**
```
âœ… Agent Health Status (all agents)
ğŸ”¥ Error Rate by Agent/Skill
ğŸ“ˆ Request Volume Trends
âš ï¸  System Resource Usage
```

---

## ğŸ¯ **Use Case Examples**

### **ğŸ” Debugging Slow Claims**
1. **Grafana**: Check workflow duration dashboard
2. **Jaeger**: Find slow trace for specific claim
3. **Prometheus**: Query agent communication latency
4. **Root Cause**: Identify bottleneck (LLM, DB, network)

### **ğŸ’° LLM Cost Optimization**  
1. **LangFuse**: Analyze token usage by task type
2. **Prometheus**: Compare model performance vs cost
3. **Grafana**: Trend analysis of daily costs
4. **Action**: Switch expensive models for simple tasks

### **ğŸ“Š Business Intelligence**
1. **Grafana**: Create claim processing KPI dashboard
2. **Prometheus**: Query success rates by workflow
3. **Analysis**: Peak usage times, common failure points
4. **Insights**: Optimize agent allocation, improve prompts

---

## ğŸ“ **Prometheus Query Examples**

### **Agent Performance**
```promql
# Agent request rate (requests/second)
rate(agent_requests_total[5m])

# Average response time by agent
avg by (source_agent) (rate(agent_request_duration_seconds_sum[5m]) / rate(agent_request_duration_seconds_count[5m]))

# Error rate percentage
rate(agent_requests_total{status="error"}[5m]) / rate(agent_requests_total[5m]) * 100
```

### **LLM Usage**
```promql
# Total tokens used per hour
sum by (model) (rate(llm_tokens_total[1h]) * 3600)

# Average LLM response time
avg by (model) (rate(llm_request_duration_seconds_sum[5m]) / rate(llm_request_duration_seconds_count[5m]))

# LLM error rate
rate(llm_requests_total{status="error"}[5m]) / rate(llm_requests_total[5m]) * 100
```

### **Business Metrics**
```promql
# Claim processing success rate
rate(workflow_executions_total{workflow_type="claim_status", status="success"}[5m]) / rate(workflow_executions_total{workflow_type="claim_status"}[5m]) * 100

# Active user sessions
active_sessions_total

# System health score (percentage of healthy agents)
avg(agent_health_status) * 100
```

---

## ğŸš¨ **Alerting Setup**

### **Critical Alerts**
```yaml
# High Error Rate
alert: HighErrorRate
expr: rate(agent_requests_total{status="error"}[5m]) / rate(agent_requests_total[5m]) > 0.05
for: 2m

# Agent Down
alert: AgentDown  
expr: agent_health_status == 0
for: 1m

# High LLM Latency
alert: HighLLMLatency
expr: histogram_quantile(0.95, rate(llm_request_duration_seconds_bucket[5m])) > 10
for: 5m
```

### **Business Alerts** 
```yaml
# Low Success Rate
alert: LowSuccessRate
expr: rate(workflow_executions_total{status="success"}[10m]) / rate(workflow_executions_total[10m]) < 0.90
for: 5m

# High Token Usage (Cost)
alert: HighTokenUsage
expr: rate(llm_tokens_total[1h]) > 100000
for: 10m
```

---

## ğŸ› ï¸ **Troubleshooting**

### **Common Issues**

**ğŸ”´ Metrics Not Appearing**
```bash
# Check if agents are exposing metrics
kubectl exec -it deployment/claims-agent -n insurance-poc -- curl localhost:9000/metrics

# Check Prometheus targets
curl http://localhost:30090/api/v1/targets
```

**ğŸ”´ Traces Not Showing**
```bash
# Check Jaeger connectivity
kubectl logs deployment/jaeger -n insurance-poc

# Verify OpenTelemetry configuration
kubectl exec -it deployment/claims-agent -n insurance-poc -- env | grep JAEGER
```

**ğŸ”´ Grafana Dashboard Issues**
```bash
# Check Grafana logs
kubectl logs deployment/grafana -n insurance-poc

# Verify data sources
curl -u admin:admin123 http://localhost:30030/api/datasources
```

### **Performance Tuning**
```bash
# Increase Prometheus retention
# Edit prometheus-config ConfigMap
retention.time=720h  # 30 days

# Scale Jaeger for high volume  
kubectl scale deployment jaeger --replicas=2 -n insurance-poc

# Optimize Grafana queries
# Use recording rules for complex queries
```

---

## ğŸ“ˆ **Advanced Features**

### **Custom Dashboards**
Create specialized dashboards for:
- **Customer Success Team**: Response times, resolution rates
- **DevOps Team**: System health, resource usage  
- **Product Team**: Feature usage, user journeys
- **Finance Team**: LLM costs, operational efficiency

### **Machine Learning Integration**
- **Anomaly Detection**: Use Prometheus data to detect unusual patterns
- **Predictive Scaling**: Forecast load based on historical metrics
- **Quality Scoring**: Track conversation quality over time

### **Integration with External Tools**
- **Slack Alerts**: Critical system notifications
- **PagerDuty**: Incident management integration
- **Jupyter Notebooks**: Advanced analytics and reporting

---

## ğŸ‰ **Best Practices**

### **ğŸ“Š Dashboard Design**
- âœ… **Focus on Business Metrics** first, technical metrics second
- âœ… **Use Consistent Time Ranges** across related panels
- âœ… **Color Code by Severity** (green=good, yellow=warning, red=critical)
- âœ… **Include Context** with annotations and descriptions

### **ğŸ“ˆ Metrics Strategy**
- âœ… **Start Simple** - Monitor key workflows first
- âœ… **Add Labels Carefully** - Too many can impact performance
- âœ… **Use Recording Rules** for expensive queries
- âœ… **Set Meaningful Thresholds** based on business impact

### **ğŸ” Tracing Best Practices**
- âœ… **Sample Appropriately** - 100% for development, 1-10% for production
- âœ… **Add Business Context** to spans (customer_id, claim_id)
- âœ… **Instrument Key Operations** - LLM calls, database queries, external APIs
- âœ… **Use Structured Logging** with correlation IDs

---

## ğŸš€ **Getting Started Checklist**

- [ ] Deploy observability stack (`./deploy_observability.sh`)
- [ ] Access Grafana dashboard (http://localhost:30030)
- [ ] Generate test traffic to populate metrics
- [ ] Explore pre-built dashboards
- [ ] Set up LangFuse for LLM observability (optional)
- [ ] Configure alerts for critical metrics
- [ ] Create custom dashboards for your team
- [ ] Document runbooks for common issues

---

**ğŸ¯ Result**: Complete visibility into your multi-agent AI system with actionable insights for optimization, debugging, and business intelligence! 