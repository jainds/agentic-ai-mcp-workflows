{
  "timestamp": "2025-06-04T14:41:26.324469",
  "overall_status": "failed",
  "test_categories": {
    "unit": {
      "status": "completed",
      "results": {
        "all_unit_tests": {
          "command": "python -m pytest tests/unit/ -v --tb=short --json-report --json-report-file=test_results_unit.json",
          "success": false,
          "output": "============================= test session starts ==============================\nplatform darwin -- Python 3.13.3, pytest-8.3.5, pluggy-1.6.0 -- /Users/piyushkumarjain/insurance-ai-poc/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.13.3', 'Platform': 'macOS-15.5-arm64-arm-64bit-Mach-O', 'Packages': {'pytest': '8.3.5', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'json-report': '1.5.0', 'metadata': '3.1.1', 'langsmith': '0.3.43', 'mock': '3.14.1', 'cov': '6.1.1', 'asyncio': '1.0.0'}}\nrootdir: /Users/piyushkumarjain/insurance-ai-poc\nconfigfile: pyproject.toml\nplugins: anyio-4.9.0, json-report-1.5.0, metadata-3.1.1, langsmith-0.3.43, mock-3.14.1, cov-6.1.1, asyncio-1.0.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 164 items\n\ntests/unit/test_agent_base.py::TestBaseAgent::test_agent_initialization PASSED [  0%]\ntests/unit/test_agent_base.py::TestBaseAgent::test_skill_registration PASSED [  1%]\ntests/unit/test_agent_base.py::TestBaseAgent::test_task_processing PASSED [  1%]\ntests/unit/test_agent_base.py::TestBaseAgent::test_task_processing_error PASSED [  2%]\ntests/unit/test_agent_base.py::TestBaseAgent::test_get_skill_info PASSED [  3%]\ntests/unit/test_agent_base.py::TestTechnicalAgent::test_technical_agent_init PASSED [  3%]\ntests/unit/test_agent_base.py::TestTechnicalAgent::test_http_client_creation PASSED [  4%]\ntests/unit/test_agent_base.py::TestTechnicalAgent::test_skill_execution PASSED [  4%]\ntests/unit/test_agent_base.py::TestDomainAgent::test_domain_agent_init PASSED [  5%]\ntests/unit/test_agent_base.py::TestDomainAgent::test_technical_agent_registration PASSED [  6%]\ntests/unit/test_agent_base.py::TestDomainAgent::test_skill_execution PASSED [  6%]\ntests/unit/test_agent_base.py::TestAgentServer::test_execute_request_handling PASSED [  7%]\ntests/unit/test_agent_base.py::TestAgentServer::test_execute_request_error PASSED [  7%]\ntests/unit/test_agent_base.py::TestAgentServer::test_health_check PASSED [  8%]\ntests/unit/test_agent_base.py::TestAgentServer::test_skills_request PASSED [  9%]\ntests/unit/test_agent_base.py::TestUtilities::test_create_task_id PASSED [  9%]\ntests/unit/test_agent_base.py::TestUtilities::test_agent_task_creation PASSED [ 10%]\ntests/unit/test_agent_base.py::TestUtilities::test_skill_decorator PASSED [ 10%]\ntests/unit/test_agent_llm_integration.py::TestSupportAgentLLMIntegration::test_handle_customer_inquiry_with_llm PASSED [ 11%]\ntests/unit/test_agent_llm_integration.py::TestSupportAgentLLMIntegration::test_extract_intent_functionality PASSED [ 12%]\ntests/unit/test_agent_llm_integration.py::TestSupportAgentLLMIntegration::test_generate_response_with_context PASSED [ 12%]\ntests/unit/test_agent_llm_integration.py::TestSupportAgentLLMIntegration::test_llm_error_handling PASSED [ 13%]\ntests/unit/test_agent_llm_integration.py::TestClaimsAgentLLMIntegration::test_claims_agent_llm_integration PASSED [ 14%]\ntests/unit/test_agent_llm_integration.py::TestTechnicalAgentLLMIntegration::test_technical_agents_initialization PASSED [ 14%]\ntests/unit/test_agent_llm_integration.py::TestAgentLLMErrorHandling::test_api_key_missing_error PASSED [ 15%]\ntests/unit/test_agent_llm_integration.py::TestAgentLLMErrorHandling::test_llm_timeout_handling PASSED [ 15%]\ntests/unit/test_agent_llm_integration.py::TestAgentLLMErrorHandling::test_llm_rate_limit_handling PASSED [ 16%]\ntests/unit/test_agent_llm_integration.py::TestAgentLLMErrorHandling::test_llm_invalid_response_handling PASSED [ 17%]\ntests/unit/test_agent_llm_integration.py::TestAgentLLMPerformance::test_llm_response_caching PASSED [ 17%]\ntests/unit/test_agent_llm_integration.py::TestAgentLLMPerformance::test_llm_token_usage_tracking PASSED [ 18%]\ntests/unit/test_agent_llm_integration.py::TestAgentLLMPerformance::test_concurrent_llm_requests PASSED [ 18%]\ntests/unit/test_agent_llm_integration.py::TestRealAgentLLMIntegration::test_real_intent_extraction PASSED [ 19%]\ntests/unit/test_agent_llm_integration.py::TestRealAgentLLMIntegration::test_real_response_generation PASSED [ 20%]\ntests/unit/test_agent_llm_integration.py::TestRealAgentLLMIntegration::test_real_end_to_end_workflow PASSED [ 20%]\ntests/unit/test_api_structure.py::TestAPIStructure::test_get_policies_basic PASSED [ 21%]\ntests/unit/test_api_structure.py::TestAPIStructure::test_get_agent_information PASSED [ 21%]\ntests/unit/test_api_structure.py::TestAPIStructure::test_get_policy_types PASSED [ 22%]\ntests/unit/test_api_structure.py::TestAPIStructure::test_get_policy_list_detailed PASSED [ 23%]\ntests/unit/test_api_structure.py::TestAPIStructure::test_get_payment_information PASSED [ 23%]\ntests/unit/test_api_structure.py::TestAPIStructure::test_get_coverage_information PASSED [ 24%]\ntests/unit/test_api_structure.py::TestAPIStructure::test_get_policy_details_specific PASSED [ 25%]\ntests/unit/test_api_structure.py::TestAPIStructure::test_get_deductibles PASSED [ 25%]\ntests/unit/test_api_structure.py::TestAPIStructure::test_get_recommendations PASSED [ 26%]\ntests/unit/test_api_structure.py::TestAPIStructure::test_invalid_customer_id PASSED [ 26%]\ntests/unit/test_api_structure.py::TestAPIStructure::test_api_data_consistency PASSED [ 27%]\ntests/unit/test_api_structure.py::TestAPIStructure::test_api_response_size_comparison PASSED [ 28%]\ntests/unit/test_api_structure.py::TestAPIValidation::test_empty_customer_id PASSED [ 28%]\ntests/unit/test_api_structure.py::TestAPIValidation::test_policy_details_with_invalid_policy_id PASSED [ 29%]\ntests/unit/test_api_structure.py::TestAPIValidation::test_api_parameter_types PASSED [ 29%]\ntests/unit/test_api_structure.py::TestAPIBusinessLogic::test_recommendations_structure PASSED [ 30%]\ntests/unit/test_api_structure.py::TestAPIBusinessLogic::test_policy_types_consistency PASSED [ 31%]\ntests/unit/test_api_structure.py::TestAPIBusinessLogic::test_coverage_completeness PASSED [ 31%]\ntests/unit/test_billing_cycle_accuracy.py::test_billing_cycle_accuracy PASSED [ 32%]\ntests/unit/test_billing_cycle_accuracy.py::test_payment_inquiry_accuracy PASSED [ 32%]\ntests/unit/test_customer_service.py::TestCustomerService::test_health_check PASSED [ 33%]\ntests/unit/test_customer_service.py::TestCustomerService::test_get_customer_existing PASSED [ 34%]\ntests/unit/test_customer_service.py::TestCustomerService::test_get_customer_not_found PASSED [ 34%]\ntests/unit/test_customer_service.py::TestCustomerService::test_get_customer_summary PASSED [ 35%]\ntests/unit/test_customer_service.py::TestCustomerService::test_list_customers PASSED [ 35%]\ntests/unit/test_customer_service.py::TestCustomerService::test_list_customers_with_status_filter PASSED [ 36%]\ntests/unit/test_customer_service.py::TestCustomerService::test_list_customers_with_pagination PASSED [ 37%]\ntests/unit/test_customer_service.py::TestCustomerService::test_create_customer PASSED [ 37%]\ntests/unit/test_customer_service.py::TestCustomerService::test_update_customer PASSED [ 38%]\ntests/unit/test_customer_service.py::TestCustomerService::test_update_customer_not_found PASSED [ 39%]\ntests/unit/test_customer_service.py::TestCustomerService::test_delete_customer PASSED [ 39%]\ntests/unit/test_customer_service.py::TestCustomerService::test_delete_customer_not_found PASSED [ 40%]\ntests/unit/test_customer_service.py::TestCustomerService::test_get_customer_policies PASSED [ 40%]\ntests/unit/test_customer_service.py::TestCustomerService::test_add_policy_to_customer PASSED [ 41%]\ntests/unit/test_customer_service.py::TestCustomerService::test_remove_policy_from_customer PASSED [ 42%]\ntests/unit/test_customer_service.py::TestCustomerService::test_search_customers PASSED [ 42%]\ntests/unit/test_customer_service.py::TestCustomerService::test_search_customers_by_email PASSED [ 43%]\ntests/unit/test_customer_service.py::TestCustomerService::test_search_customers_no_results PASSED [ 43%]\ntests/unit/test_customer_service.py::TestCustomerModels::test_customer_response_from_customer PASSED [ 44%]\ntests/unit/test_customer_service.py::TestCustomerModels::test_customer_status_enum PASSED [ 45%]\ntests/unit/test_customer_service.py::TestCustomerModels::test_address_model PASSED [ 45%]\ntests/unit/test_customer_service.py::TestCustomerModels::test_contact_info_model PASSED [ 46%]\ntests/unit/test_domain_agent_core.py::TestDomainAgentCore::test_customer_id_pattern_matching PASSED [ 46%]\ntests/unit/test_domain_agent_core.py::TestDomainAgentCore::test_intent_classification_patterns PASSED [ 47%]\ntests/unit/test_domain_agent_core.py::TestDomainAgentCore::test_response_formatting_structure PASSED [ 48%]\ntests/unit/test_domain_agent_core.py::TestDomainAgentConfiguration::test_a2a_client_configuration PASSED [ 48%]\ntests/unit/test_domain_agent_core.py::TestDomainAgentConfiguration::test_openai_fallback_configuration PASSED [ 49%]\ntests/unit/test_domain_agent_core.py::TestDomainAgentWorkflows::test_customer_conversation_workflow PASSED [ 50%]\ntests/unit/test_domain_agent_core.py::TestDomainAgentWorkflows::test_session_based_processing PASSED [ 50%]\ntests/unit/test_domain_agent_core.py::TestDomainAgentErrorHandling::test_technical_agent_unavailable_fallback PASSED [ 51%]\ntests/unit/test_domain_agent_core.py::TestDomainAgentErrorHandling::test_invalid_customer_id_handling PASSED [ 51%]\ntests/unit/test_intelligent_agent.py::TestIntelligentAgentCore::test_execution_plan_validation_logic PASSED [ 52%]\ntests/unit/test_intelligent_agent.py::TestIntelligentAgentCore::test_mcp_request_validation_logic PASSED [ 53%]\ntests/unit/test_intelligent_agent.py::TestIntelligentAgentCore::test_tool_parameter_validation_logic PASSED [ 53%]\ntests/unit/test_intelligent_agent.py::TestIntelligentAgentCore::test_json_parsing_from_llm_response PASSED [ 54%]\ntests/unit/test_intelligent_agent.py::TestServiceDiscoveryIntegration::test_tool_registry_management PASSED [ 54%]\ntests/unit/test_intelligent_agent.py::TestServiceDiscoveryIntegration::test_tools_description_building PASSED [ 55%]\ntests/unit/test_intelligent_agent.py::TestBusinessLogicValidation::test_multi_tool_execution_planning PASSED [ 56%]\ntests/unit/test_intelligent_agent.py::TestBusinessLogicValidation::test_error_handling_strategies PASSED [ 56%]\ntests/unit/test_llm_client.py::TestOpenRouterClient::test_client_initialization_with_env_key PASSED [ 57%]\ntests/unit/test_llm_client.py::TestOpenRouterClient::test_client_initialization_with_explicit_key PASSED [ 57%]\ntests/unit/test_llm_client.py::TestOpenRouterClient::test_client_initialization_without_key_raises_error PASSED [ 58%]\ntests/unit/test_llm_client.py::TestOpenRouterClient::test_chat_completion_success PASSED [ 59%]\ntests/unit/test_llm_client.py::TestOpenRouterClient::test_chat_completion_with_llm_message_objects PASSED [ 59%]\ntests/unit/test_llm_client.py::TestOpenRouterClient::test_chat_completion_with_fallback FAILED [ 60%]\ntests/unit/test_llm_client.py::TestOpenRouterClient::test_chat_completion_failure_without_fallback PASSED [ 60%]\ntests/unit/test_llm_client.py::TestOpenRouterClient::test_embedding_success PASSED [ 61%]\ntests/unit/test_llm_client.py::TestOpenRouterClient::test_make_request_http_error PASSED [ 62%]\ntests/unit/test_llm_client.py::TestOpenRouterClient::test_make_request_network_error PASSED [ 62%]\ntests/unit/test_llm_client.py::TestOpenRouterClient::test_get_provider_from_model PASSED [ 63%]\ntests/unit/test_llm_client.py::TestOpenRouterClient::test_client_close PASSED [ 64%]\ntests/unit/test_llm_client.py::TestLLMSkillMixin::test_llm_chat_success PASSED [ 64%]\ntests/unit/test_llm_client.py::TestLLMSkillMixin::test_llm_chat_with_system_prompt PASSED [ 65%]\ntests/unit/test_llm_client.py::TestLLMSkillMixin::test_extract_intent_success PASSED [ 65%]\ntests/unit/test_llm_client.py::TestLLMSkillMixin::test_extract_intent_invalid_json PASSED [ 66%]\ntests/unit/test_llm_client.py::TestLLMSkillMixin::test_generate_response_with_context PASSED [ 67%]\ntests/unit/test_llm_client.py::TestLLMSkillMixin::test_close_llm_client PASSED [ 67%]\ntests/unit/test_llm_client.py::TestRealAPIIntegration::test_real_chat_completion PASSED [ 68%]\ntests/unit/test_llm_client.py::TestRealAPIIntegration::test_real_embedding SKIPPED [ 68%]\ntests/unit/test_llm_client.py::TestRealAPIIntegration::test_real_api_key_validation PASSED [ 69%]\ntests/unit/test_llm_simple.py::test_llm_intent PASSED                    [ 70%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_load_data_success PASSED [ 70%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_load_data_file_not_found PASSED [ 71%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_load_data_invalid_json PASSED [ 71%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_load_data_empty_file PASSED [ 72%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_get_customer_policies_found PASSED [ 73%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_get_customer_policies_not_found PASSED [ 73%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_get_customer_policies_empty_data PASSED [ 74%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_get_customer_policies_malformed_data PASSED [ 75%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_get_customer_policies_missing_fields PASSED [ 75%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_get_customer_policies_case_sensitivity PASSED [ 76%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_get_customer_policies_whitespace_handling PASSED [ 76%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_get_customer_policies_special_characters FAILED [ 77%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_get_customer_policies_numeric_customer_id FAILED [ 78%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_logging_output PASSED [ 78%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_logging_not_found PASSED [ 79%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_mcp_tool_registration PASSED [ 79%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_tool_function_signature PASSED [ 80%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_data_file_path PASSED [ 81%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_policy_data_structure_validation PASSED [ 81%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_empty_customer_id PASSED [ 82%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_none_customer_id PASSED [ 82%]\ntests/unit/test_policy_server.py::TestPolicyServer::test_large_dataset_performance PASSED [ 83%]\ntests/unit/test_service_discovery.py::TestServiceEndpoint::test_service_endpoint_creation PASSED [ 84%]\ntests/unit/test_service_discovery.py::TestServiceEndpoint::test_service_endpoint_defaults PASSED [ 84%]\ntests/unit/test_service_discovery.py::TestDiscoveredTool::test_discovered_tool_creation PASSED [ 85%]\ntests/unit/test_service_discovery.py::TestServiceCapabilities::test_service_capabilities_creation PASSED [ 85%]\ntests/unit/test_service_discovery.py::TestServiceDiscovery::test_initialization PASSED [ 86%]\ntests/unit/test_service_discovery.py::TestServiceDiscovery::test_get_default_services PASSED [ 87%]\ntests/unit/test_service_discovery.py::TestServiceDiscovery::test_discover_service_mock PASSED [ 87%]\ntests/unit/test_service_discovery.py::TestServiceDiscovery::test_register_service_capabilities PASSED [ 88%]\ntests/unit/test_service_discovery.py::TestServiceDiscovery::test_get_available_tools PASSED [ 89%]\ntests/unit/test_service_discovery.py::TestServiceDiscovery::test_get_tool_by_name PASSED [ 89%]\ntests/unit/test_service_discovery.py::TestServiceDiscovery::test_build_tools_description PASSED [ 90%]\ntests/unit/test_service_discovery.py::TestServiceDiscovery::test_get_service_summary PASSED [ 90%]\ntests/unit/test_service_discovery.py::TestServiceDiscovery::test_unregister_service_capabilities PASSED [ 91%]\ntests/unit/test_service_discovery.py::TestServiceDiscovery::test_refresh_service_mock PASSED [ 92%]\ntests/unit/test_service_discovery.py::TestServiceDiscovery::test_refresh_nonexistent_service PASSED [ 92%]\ntests/unit/test_service_discovery.py::TestServiceDiscovery::test_discover_all_services_mixed_results PASSED [ 93%]\ntests/unit/test_technical_agent_integration.py::TestTechnicalAgentCore::test_request_parsing_logic PASSED [ 93%]\ntests/unit/test_technical_agent_integration.py::TestTechnicalAgentCore::test_mcp_request_validation PASSED [ 94%]\ntests/unit/test_technical_agent_integration.py::TestTechnicalAgentCore::test_response_processing PASSED [ 95%]\ntests/unit/test_technical_agent_integration.py::TestTechnicalAgentConfiguration::test_service_discovery_configuration PASSED [ 95%]\ntests/unit/test_technical_agent_integration.py::TestTechnicalAgentConfiguration::test_a2a_server_configuration PASSED [ 96%]\ntests/unit/test_technical_agent_integration.py::TestTechnicalAgentWorkflows::test_health_check_workflow PASSED [ 96%]\ntests/unit/test_technical_agent_integration.py::TestTechnicalAgentWorkflows::test_service_refresh_workflow PASSED [ 97%]\ntests/unit/test_technical_agent_integration.py::TestTechnicalAgentErrorHandling::test_policy_server_unavailable PASSED [ 98%]\ntests/unit/test_technical_agent_integration.py::TestTechnicalAgentErrorHandling::test_openai_unavailable_fallback PASSED [ 98%]\ntests/unit/test_technical_agent_integration.py::TestTechnicalAgentBusinessLogic::test_intelligent_tool_selection PASSED [ 99%]\ntests/unit/test_technical_agent_integration.py::TestTechnicalAgentBusinessLogic::test_multi_tool_execution_planning PASSED [100%]\n\n=================================== FAILURES ===================================\n___________ TestOpenRouterClient.test_chat_completion_with_fallback ____________\ntests/unit/test_llm_client.py:126: in test_chat_completion_with_fallback\n    response = await client.chat_completion(messages, use_fallback=True)\nagents/llm_client.py:99: in chat_completion\n    response = await self._make_request(\"/chat/completions\", payload)\n/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:2330: in _execute_mock_call\n    raise result\nE   httpx.HTTPStatusError: Model unavailable\n------------------------------ Captured log call -------------------------------\nERROR    agents.llm_client:llm_client.py:111 Error with model openai/gpt-4o-mini: Model unavailable\n________ TestPolicyServer.test_get_customer_policies_special_characters ________\ntests/unit/test_policy_server.py:214: in test_get_customer_policies_special_characters\n    assert len(result) == 2\nE   AssertionError: assert 1 == 2\nE    +  where 1 = len([{'id': 'POL-001', 'type': 'Auto Insurance', 'status': 'Active', 'premium': 1200.0, 'coverage_amount': 50000, 'deductible': 500, 'start_date': '2024-01-01', 'end_date': '2024-12-31', 'billing_cycle': None, 'next_payment_due': None, 'payment_method': None, 'assigned_agent': {}, 'details': {}}])\n_______ TestPolicyServer.test_get_customer_policies_numeric_customer_id ________\ntests/unit/test_policy_server.py:241: in test_get_customer_policies_numeric_customer_id\n    assert len(result) == 2\nE   AssertionError: assert 1 == 2\nE    +  where 1 = len([{'id': 'POL-001', 'type': 'Auto Insurance', 'status': 'Active', 'premium': 1200.0, 'coverage_amount': 50000, 'deductible': 500, 'start_date': '2024-01-01', 'end_date': '2024-12-31', 'billing_cycle': None, 'next_payment_due': None, 'payment_method': None, 'assigned_agent': {}, 'details': {}}])\n--------------------------------- JSON report ----------------------------------\nreport saved to: test_results_unit.json\n================================ tests coverage ================================\n_______________ coverage: platform darwin, python 3.13.3-final-0 _______________\n\nName                                   Stmts   Miss  Cover   Missing\n--------------------------------------------------------------------\nagents/base.py                           176     31    82%   104, 158, 165-177, 199-221, 226, 297, 307\nagents/domain/claims_domain_agent.py     224    194    13%   33-60, 69-213, 222-336, 345-396, 404-438, 444-472, 477-506, 514-534, 542-627, 632-639, 643\nagents/domain/support_agent.py           172    109    37%   46, 48, 53-67, 80, 95, 109, 118, 159-161, 170-262, 271-320, 335-343, 358-360, 369-398, 406-468, 473-480, 484\nagents/llm_client.py                     141     14    90%   114-115, 144-146, 331, 333, 335, 339-345\nagents/mcp_tools.py                      207    207     0%   1-499\nagents/technical/claims_agent.py         177    132    25%   17-25, 33-41, 49-57, 65-73, 81-97, 105-113, 121-129, 137-149, 157-173, 181-189, 197-213, 221-233, 241-256, 264-279, 287-302, 310-318, 326-351, 359-404, 409-416, 420\nagents/technical/customer_agent.py        98     73    26%   17-25, 33-41, 49-61, 69-77, 85-93, 101-113, 121-144, 152-197, 202-209, 213\nagents/technical/policy_agent.py         138    103    25%   17-25, 33-41, 49-57, 65-73, 81-89, 97-109, 117-129, 137-162, 170-178, 186-198, 206-218, 226-238, 246-291, 296-303, 307\nservices/customer/app.py                 104     14    87%   99, 150, 153-156, 178, 191, 204, 227-228, 236, 241-243\nservices/customer/models.py               63      5    92%   77-82\nui/__init__.py                             0      0   100%\nui/components/__init__.py                  7      7     0%   6-13\nui/components/agent_client.py             97     97     0%   6-263\nui/components/auth.py                     49     49     0%   6-86\nui/components/chat.py                     79     79     0%   6-137\nui/components/config.py                   21     21     0%   6-60\nui/components/monitoring.py              138    138     0%   6-231\nui/components/thinking.py                138    138     0%   6-257\nui/streamlit_app.py                      106    106     0%   7-210\n--------------------------------------------------------------------\nTOTAL                                   2135   1517    29%\nCoverage HTML written to dir htmlcov\n=========================== short test summary info ============================\nFAILED tests/unit/test_llm_client.py::TestOpenRouterClient::test_chat_completion_with_fallback - httpx.HTTPStatusError: Model unavailable\nFAILED tests/unit/test_policy_server.py::TestPolicyServer::test_get_customer_policies_special_characters - AssertionError: assert 1 == 2\n +  where 1 = len([{'id': 'POL-001', 'type': 'Auto Insurance', 'status': 'Active', 'premium': 1200.0, 'coverage_amount': 50000, 'deductible': 500, 'start_date': '2024-01-01', 'end_date': '2024-12-31', 'billing_cycle': None, 'next_payment_due': None, 'payment_method': None, 'assigned_agent': {}, 'details': {}}])\nFAILED tests/unit/test_policy_server.py::TestPolicyServer::test_get_customer_policies_numeric_customer_id - AssertionError: assert 1 == 2\n +  where 1 = len([{'id': 'POL-001', 'type': 'Auto Insurance', 'status': 'Active', 'premium': 1200.0, 'coverage_amount': 50000, 'deductible': 500, 'start_date': '2024-01-01', 'end_date': '2024-12-31', 'billing_cycle': None, 'next_payment_due': None, 'payment_method': None, 'assigned_agent': {}, 'details': {}}])\n================== 3 failed, 160 passed, 1 skipped in 43.14s ===================\n",
          "errors": "/Users/piyushkumarjain/insurance-ai-poc/.venv/lib/python3.13/site-packages/pytest_asyncio/plugin.py:208: PytestDeprecationWarning: The configuration option \"asyncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))\n"
        }
      }
    },
    "integration": {
      "status": "completed",
      "results": {
        "all_integration_tests": {
          "command": "python -m pytest tests/integration/ -v --tb=short --json-report --json-report-file=test_results_integration.json",
          "success": false,
          "output": "============================= test session starts ==============================\nplatform darwin -- Python 3.13.3, pytest-8.3.5, pluggy-1.6.0 -- /Users/piyushkumarjain/insurance-ai-poc/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.13.3', 'Platform': 'macOS-15.5-arm64-arm-64bit-Mach-O', 'Packages': {'pytest': '8.3.5', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'json-report': '1.5.0', 'metadata': '3.1.1', 'langsmith': '0.3.43', 'mock': '3.14.1', 'cov': '6.1.1', 'asyncio': '1.0.0'}}\nrootdir: /Users/piyushkumarjain/insurance-ai-poc\nconfigfile: pyproject.toml\nplugins: anyio-4.9.0, json-report-1.5.0, metadata-3.1.1, langsmith-0.3.43, mock-3.14.1, cov-6.1.1, asyncio-1.0.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 124 items / 2 errors\n\n==================================== ERRORS ====================================\n___________ ERROR collecting tests/integration/test_e2e_workflows.py ___________\n'performance' not found in `markers` configuration option\n______ ERROR collecting tests/integration/test_python_a2a_integration.py _______\nImportError while importing test module '/Users/piyushkumarjain/insurance-ai-poc/tests/integration/test_python_a2a_integration.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n.venv/lib/python3.13/site-packages/_pytest/python.py:493: in importtestmodule\n    mod = import_path(\n.venv/lib/python3.13/site-packages/_pytest/pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/importlib/__init__.py:88: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:935: in _load_unlocked\n    ???\n.venv/lib/python3.13/site-packages/_pytest/assertion/rewrite.py:185: in exec_module\n    exec(co, module.__dict__)\ntests/integration/test_python_a2a_integration.py:22: in <module>\n    from agents.shared.python_a2a_base import PythonA2AAgent, PythonA2AClientWrapper\nE   ModuleNotFoundError: No module named 'agents.shared'\n--------------------------------- JSON report ----------------------------------\nreport saved to: test_results_integration.json\n================================ tests coverage ================================\n_______________ coverage: platform darwin, python 3.13.3-final-0 _______________\n\nName                                   Stmts   Miss  Cover   Missing\n--------------------------------------------------------------------\nagents/base.py                           176    100    43%   51-52, 71-76, 80-91, 95-99, 104, 108-127, 131-138, 145-147, 151-153, 157-161, 165-177, 181-182, 189-190, 194-195, 199-221, 225-229, 236, 240-260, 268, 278, 292, 297, 307\nagents/domain/claims_domain_agent.py     224    199    11%   13-25, 33-60, 69-213, 222-336, 345-396, 404-438, 444-472, 477-506, 514-534, 542-627, 632-639, 643\nagents/domain/support_agent.py           172    149    13%   13-25, 33-67, 76-161, 170-262, 271-320, 329-360, 369-398, 406-468, 473-480, 484\nagents/llm_client.py                     141     99    30%   38-56, 74-124, 133-146, 150-163, 167-169, 173, 246-247, 258-269, 273-309, 317-345, 354-367, 371-372\nagents/mcp_tools.py                      207    207     0%   1-499\nui/__init__.py                             0      0   100%\nui/components/__init__.py                  7      7     0%   6-13\nui/components/agent_client.py             97     97     0%   6-263\nui/components/auth.py                     49     49     0%   6-86\nui/components/chat.py                     79     79     0%   6-137\nui/components/config.py                   21     21     0%   6-60\nui/components/monitoring.py              138    138     0%   6-231\nui/components/thinking.py                138    138     0%   6-257\nui/streamlit_app.py                      106    106     0%   7-210\n--------------------------------------------------------------------\nTOTAL                                   1555   1389    11%\nCoverage HTML written to dir htmlcov\n=========================== short test summary info ============================\nERROR tests/integration/test_e2e_workflows.py - Failed: 'performance' not found in `markers` configuration option\nERROR tests/integration/test_python_a2a_integration.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 2 errors during collection !!!!!!!!!!!!!!!!!!!!\n============================== 2 errors in 2.10s ===============================\n",
          "errors": "/Users/piyushkumarjain/insurance-ai-poc/.venv/lib/python3.13/site-packages/pytest_asyncio/plugin.py:208: PytestDeprecationWarning: The configuration option \"asyncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))\n"
        }
      }
    },
    "e2e": {
      "status": "completed",
      "results": {
        "all_e2e_tests": {
          "command": "python -m pytest tests/e2e/ -v --tb=short --json-report --json-report-file=test_results_e2e.json",
          "success": false,
          "output": "============================= test session starts ==============================\nplatform darwin -- Python 3.13.3, pytest-8.3.5, pluggy-1.6.0 -- /Users/piyushkumarjain/insurance-ai-poc/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.13.3', 'Platform': 'macOS-15.5-arm64-arm-64bit-Mach-O', 'Packages': {'pytest': '8.3.5', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'json-report': '1.5.0', 'metadata': '3.1.1', 'langsmith': '0.3.43', 'mock': '3.14.1', 'cov': '6.1.1', 'asyncio': '1.0.0'}}\nrootdir: /Users/piyushkumarjain/insurance-ai-poc\nconfigfile: pyproject.toml\nplugins: anyio-4.9.0, json-report-1.5.0, metadata-3.1.1, langsmith-0.3.43, mock-3.14.1, cov-6.1.1, asyncio-1.0.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 25 items\n\ntests/e2e/test_complete_system_flow.py::TestCompleteSystemFlow::test_complete_policy_inquiry_flow FAILED [  4%]\ntests/e2e/test_complete_system_flow.py::TestCompleteSystemFlow::test_complete_claim_filing_flow FAILED [  8%]\ntests/e2e/test_complete_system_flow.py::TestCompleteSystemFlow::test_technical_agent_mcp_integration FAILED [ 12%]\ntests/e2e/test_complete_system_flow.py::TestCompleteSystemFlow::test_error_handling_and_resilience FAILED [ 16%]\ntests/e2e/test_complete_system_flow.py::TestCompleteSystemFlow::test_conversation_context_management FAILED [ 20%]\ntests/e2e/test_complete_system_flow.py::TestCompleteSystemFlow::test_performance_and_response_times FAILED [ 24%]\ntests/e2e/test_complete_system_flow.py::TestServiceHealth::test_fastmcp_services_health SKIPPED [ 28%]\ntests/e2e/test_complete_system_flow.py::TestServiceHealth::test_domain_agent_health SKIPPED [ 32%]\ntests/e2e/test_complete_system_flow.py::TestServiceHealth::test_technical_agent_health SKIPPED1)) [ 36%]\ntests/e2e/test_complete_system_flow.py::test_system_readiness SKIPPEDClaims Service, Analytics Service) [ 40%]\ntests/e2e/test_domain_e2e_comprehensive.py::TestDomainAgentE2EFlow::test_complete_customer_interaction_flow PASSED [ 44%]\ntests/e2e/test_domain_e2e_comprehensive.py::TestDomainAgentE2EFlow::test_error_handling_e2e_flow PASSED [ 48%]\ntests/e2e/test_domain_e2e_comprehensive.py::TestDomainAgentE2EFlow::test_multi_turn_conversation_flow PASSED [ 52%]\ntests/e2e/test_domain_e2e_comprehensive.py::TestDomainAgentPerformance::test_response_time_performance PASSED [ 56%]\ntests/e2e/test_domain_e2e_comprehensive.py::TestDomainAgentPerformance::test_concurrent_request_handling PASSED [ 60%]\ntests/e2e/test_focused_apis.py::TestFocusedAPIsE2E::test_customer_service_quick_policy_lookup PASSED [ 64%]\ntests/e2e/test_focused_apis.py::TestFocusedAPIsE2E::test_billing_inquiry_scenario PASSED [ 68%]\ntests/e2e/test_focused_apis.py::TestFocusedAPIsE2E::test_agent_contact_request PASSED [ 72%]\ntests/e2e/test_focused_apis.py::TestFocusedAPIsE2E::test_coverage_verification_scenario PASSED [ 76%]\ntests/e2e/test_focused_apis.py::TestFocusedAPIsE2E::test_new_customer_recommendations PASSED [ 80%]\ntests/e2e/test_focused_apis.py::TestFocusedAPIsE2E::test_multi_api_customer_overview PASSED [ 84%]\ntests/e2e/test_focused_apis.py::TestFocusedAPIsE2E::test_policy_renewal_workflow PASSED [ 88%]\ntests/e2e/test_focused_apis.py::TestFocusedAPIsE2E::test_claims_preparation_scenario PASSED [ 92%]\ntests/e2e/test_focused_apis.py::TestAPIPerformanceComparison::test_response_time_comparison PASSED [ 96%]\ntests/e2e/test_focused_apis.py::TestAPIPerformanceComparison::test_data_transfer_efficiency PASSED [100%]\n\n=================================== FAILURES ===================================\n___________ TestCompleteSystemFlow.test_complete_policy_inquiry_flow ___________\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:101: in map_httpcore_exceptions\n    yield\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:394: in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py:256: in handle_async_request\n    raise exc from None\n.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py:236: in handle_async_request\n    response = await connection.handle_async_request(\n.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:101: in handle_async_request\n    raise exc\n.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:78: in handle_async_request\n    stream = await self._connect(request)\n.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:124: in _connect\n    stream = await self._network_backend.connect_tcp(**kwargs)\n.venv/lib/python3.13/site-packages/httpcore/_backends/auto.py:31: in connect_tcp\n    return await self._backend.connect_tcp(\n.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py:113: in connect_tcp\n    with map_exceptions(exc_map):\n/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:162: in __exit__\n    self.gen.throw(value)\n.venv/lib/python3.13/site-packages/httpcore/_exceptions.py:14: in map_exceptions\n    raise to_exc(exc) from exc\nE   httpcore.ConnectError: All connection attempts failed\n\nThe above exception was the direct cause of the following exception:\ntests/e2e/test_complete_system_flow.py:88: in test_complete_policy_inquiry_flow\n    response = await client.post(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1859: in post\n    return await self.request(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1540: in request\n    return await self.send(request, auth=auth, follow_redirects=follow_redirects)\n.venv/lib/python3.13/site-packages/httpx/_client.py:1629: in send\n    response = await self._send_handling_auth(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1657: in _send_handling_auth\n    response = await self._send_handling_redirects(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1694: in _send_handling_redirects\n    response = await self._send_single_request(request)\n.venv/lib/python3.13/site-packages/httpx/_client.py:1730: in _send_single_request\n    response = await transport.handle_async_request(request)\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:393: in handle_async_request\n    with map_httpcore_exceptions():\n/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:162: in __exit__\n    self.gen.throw(value)\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:118: in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nE   httpx.ConnectError: All connection attempts failed\n____________ TestCompleteSystemFlow.test_complete_claim_filing_flow ____________\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:101: in map_httpcore_exceptions\n    yield\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:394: in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py:256: in handle_async_request\n    raise exc from None\n.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py:236: in handle_async_request\n    response = await connection.handle_async_request(\n.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:101: in handle_async_request\n    raise exc\n.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:78: in handle_async_request\n    stream = await self._connect(request)\n.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:124: in _connect\n    stream = await self._network_backend.connect_tcp(**kwargs)\n.venv/lib/python3.13/site-packages/httpcore/_backends/auto.py:31: in connect_tcp\n    return await self._backend.connect_tcp(\n.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py:113: in connect_tcp\n    with map_exceptions(exc_map):\n/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:162: in __exit__\n    self.gen.throw(value)\n.venv/lib/python3.13/site-packages/httpcore/_exceptions.py:14: in map_exceptions\n    raise to_exc(exc) from exc\nE   httpcore.ConnectError: All connection attempts failed\n\nThe above exception was the direct cause of the following exception:\ntests/e2e/test_complete_system_flow.py:150: in test_complete_claim_filing_flow\n    response = await client.post(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1859: in post\n    return await self.request(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1540: in request\n    return await self.send(request, auth=auth, follow_redirects=follow_redirects)\n.venv/lib/python3.13/site-packages/httpx/_client.py:1629: in send\n    response = await self._send_handling_auth(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1657: in _send_handling_auth\n    response = await self._send_handling_redirects(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1694: in _send_handling_redirects\n    response = await self._send_single_request(request)\n.venv/lib/python3.13/site-packages/httpx/_client.py:1730: in _send_single_request\n    response = await transport.handle_async_request(request)\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:393: in handle_async_request\n    with map_httpcore_exceptions():\n/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:162: in __exit__\n    self.gen.throw(value)\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:118: in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nE   httpx.ConnectError: All connection attempts failed\n_________ TestCompleteSystemFlow.test_technical_agent_mcp_integration __________\ntests/e2e/test_complete_system_flow.py:212: in test_technical_agent_mcp_integration\n    assert response.status_code == 200\nE   assert 405 == 200\nE    +  where 405 = <Response [405 METHOD NOT ALLOWED]>.status_code\n__________ TestCompleteSystemFlow.test_error_handling_and_resilience ___________\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:101: in map_httpcore_exceptions\n    yield\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:394: in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py:256: in handle_async_request\n    raise exc from None\n.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py:236: in handle_async_request\n    response = await connection.handle_async_request(\n.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:101: in handle_async_request\n    raise exc\n.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:78: in handle_async_request\n    stream = await self._connect(request)\n.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:124: in _connect\n    stream = await self._network_backend.connect_tcp(**kwargs)\n.venv/lib/python3.13/site-packages/httpcore/_backends/auto.py:31: in connect_tcp\n    return await self._backend.connect_tcp(\n.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py:113: in connect_tcp\n    with map_exceptions(exc_map):\n/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:162: in __exit__\n    self.gen.throw(value)\n.venv/lib/python3.13/site-packages/httpcore/_exceptions.py:14: in map_exceptions\n    raise to_exc(exc) from exc\nE   httpcore.ConnectError: All connection attempts failed\n\nThe above exception was the direct cause of the following exception:\ntests/e2e/test_complete_system_flow.py:243: in test_error_handling_and_resilience\n    response = await client.post(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1859: in post\n    return await self.request(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1540: in request\n    return await self.send(request, auth=auth, follow_redirects=follow_redirects)\n.venv/lib/python3.13/site-packages/httpx/_client.py:1629: in send\n    response = await self._send_handling_auth(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1657: in _send_handling_auth\n    response = await self._send_handling_redirects(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1694: in _send_handling_redirects\n    response = await self._send_single_request(request)\n.venv/lib/python3.13/site-packages/httpx/_client.py:1730: in _send_single_request\n    response = await transport.handle_async_request(request)\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:393: in handle_async_request\n    with map_httpcore_exceptions():\n/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:162: in __exit__\n    self.gen.throw(value)\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:118: in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nE   httpx.ConnectError: All connection attempts failed\n_________ TestCompleteSystemFlow.test_conversation_context_management __________\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:101: in map_httpcore_exceptions\n    yield\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:394: in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py:256: in handle_async_request\n    raise exc from None\n.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py:236: in handle_async_request\n    response = await connection.handle_async_request(\n.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:101: in handle_async_request\n    raise exc\n.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:78: in handle_async_request\n    stream = await self._connect(request)\n.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:124: in _connect\n    stream = await self._network_backend.connect_tcp(**kwargs)\n.venv/lib/python3.13/site-packages/httpcore/_backends/auto.py:31: in connect_tcp\n    return await self._backend.connect_tcp(\n.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py:113: in connect_tcp\n    with map_exceptions(exc_map):\n/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:162: in __exit__\n    self.gen.throw(value)\n.venv/lib/python3.13/site-packages/httpcore/_exceptions.py:14: in map_exceptions\n    raise to_exc(exc) from exc\nE   httpcore.ConnectError: All connection attempts failed\n\nThe above exception was the direct cause of the following exception:\ntests/e2e/test_complete_system_flow.py:291: in test_conversation_context_management\n    response1 = await client.post(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1859: in post\n    return await self.request(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1540: in request\n    return await self.send(request, auth=auth, follow_redirects=follow_redirects)\n.venv/lib/python3.13/site-packages/httpx/_client.py:1629: in send\n    response = await self._send_handling_auth(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1657: in _send_handling_auth\n    response = await self._send_handling_redirects(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1694: in _send_handling_redirects\n    response = await self._send_single_request(request)\n.venv/lib/python3.13/site-packages/httpx/_client.py:1730: in _send_single_request\n    response = await transport.handle_async_request(request)\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:393: in handle_async_request\n    with map_httpcore_exceptions():\n/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:162: in __exit__\n    self.gen.throw(value)\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:118: in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nE   httpx.ConnectError: All connection attempts failed\n__________ TestCompleteSystemFlow.test_performance_and_response_times __________\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:101: in map_httpcore_exceptions\n    yield\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:394: in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py:256: in handle_async_request\n    raise exc from None\n.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py:236: in handle_async_request\n    response = await connection.handle_async_request(\n.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:101: in handle_async_request\n    raise exc\n.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:78: in handle_async_request\n    stream = await self._connect(request)\n.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:124: in _connect\n    stream = await self._network_backend.connect_tcp(**kwargs)\n.venv/lib/python3.13/site-packages/httpcore/_backends/auto.py:31: in connect_tcp\n    return await self._backend.connect_tcp(\n.venv/lib/python3.13/site-packages/httpcore/_backends/anyio.py:113: in connect_tcp\n    with map_exceptions(exc_map):\n/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:162: in __exit__\n    self.gen.throw(value)\n.venv/lib/python3.13/site-packages/httpcore/_exceptions.py:14: in map_exceptions\n    raise to_exc(exc) from exc\nE   httpcore.ConnectError: All connection attempts failed\n\nThe above exception was the direct cause of the following exception:\ntests/e2e/test_complete_system_flow.py:340: in test_performance_and_response_times\n    response = await client.post(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1859: in post\n    return await self.request(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1540: in request\n    return await self.send(request, auth=auth, follow_redirects=follow_redirects)\n.venv/lib/python3.13/site-packages/httpx/_client.py:1629: in send\n    response = await self._send_handling_auth(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1657: in _send_handling_auth\n    response = await self._send_handling_redirects(\n.venv/lib/python3.13/site-packages/httpx/_client.py:1694: in _send_handling_redirects\n    response = await self._send_single_request(request)\n.venv/lib/python3.13/site-packages/httpx/_client.py:1730: in _send_single_request\n    response = await transport.handle_async_request(request)\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:393: in handle_async_request\n    with map_httpcore_exceptions():\n/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:162: in __exit__\n    self.gen.throw(value)\n.venv/lib/python3.13/site-packages/httpx/_transports/default.py:118: in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nE   httpx.ConnectError: All connection attempts failed\n--------------------------------- JSON report ----------------------------------\nreport saved to: test_results_e2e.json\n================================ tests coverage ================================\n_______________ coverage: platform darwin, python 3.13.3-final-0 _______________\n\nName                            Stmts   Miss  Cover   Missing\n-------------------------------------------------------------\nagents/base.py                    176    176     0%   1-307\nagents/llm_client.py              141    141     0%   1-372\nagents/mcp_tools.py               207    207     0%   1-499\nui/__init__.py                      0      0   100%\nui/components/__init__.py           7      7     0%   6-13\nui/components/agent_client.py      97     97     0%   6-263\nui/components/auth.py              49     49     0%   6-86\nui/components/chat.py              79     79     0%   6-137\nui/components/config.py            21     21     0%   6-60\nui/components/monitoring.py       138    138     0%   6-231\nui/components/thinking.py         138    138     0%   6-257\nui/streamlit_app.py               106    106     0%   7-210\n-------------------------------------------------------------\nTOTAL                            1159   1159     0%\nCoverage HTML written to dir htmlcov\n=========================== short test summary info ============================\nFAILED tests/e2e/test_complete_system_flow.py::TestCompleteSystemFlow::test_complete_policy_inquiry_flow - httpx.ConnectError: All connection attempts failed\nFAILED tests/e2e/test_complete_system_flow.py::TestCompleteSystemFlow::test_complete_claim_filing_flow - httpx.ConnectError: All connection attempts failed\nFAILED tests/e2e/test_complete_system_flow.py::TestCompleteSystemFlow::test_technical_agent_mcp_integration - assert 405 == 200\n +  where 405 = <Response [405 METHOD NOT ALLOWED]>.status_code\nFAILED tests/e2e/test_complete_system_flow.py::TestCompleteSystemFlow::test_error_handling_and_resilience - httpx.ConnectError: All connection attempts failed\nFAILED tests/e2e/test_complete_system_flow.py::TestCompleteSystemFlow::test_conversation_context_management - httpx.ConnectError: All connection attempts failed\nFAILED tests/e2e/test_complete_system_flow.py::TestCompleteSystemFlow::test_performance_and_response_times - httpx.ConnectError: All connection attempts failed\n=================== 6 failed, 15 passed, 4 skipped in 2.44s ====================\n",
          "errors": "/Users/piyushkumarjain/insurance-ai-poc/.venv/lib/python3.13/site-packages/pytest_asyncio/plugin.py:208: PytestDeprecationWarning: The configuration option \"asyncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))\n/Users/piyushkumarjain/insurance-ai-poc/.venv/lib/python3.13/site-packages/coverage/control.py:915: CoverageWarning: No data was collected. (no-data-collected)\n  self._warn(\"No data was collected.\", slug=\"no-data-collected\")\n"
        }
      }
    },
    "system": {
      "status": "completed",
      "results": {
        "k8s_system_tests": {
          "command": "python -m pytest tests/k8s/ -v --tb=short --json-report --json-report-file=test_results_system.json",
          "success": false,
          "output": "============================= test session starts ==============================\nplatform darwin -- Python 3.13.3, pytest-8.3.5, pluggy-1.6.0 -- /Users/piyushkumarjain/insurance-ai-poc/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.13.3', 'Platform': 'macOS-15.5-arm64-arm-64bit-Mach-O', 'Packages': {'pytest': '8.3.5', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'json-report': '1.5.0', 'metadata': '3.1.1', 'langsmith': '0.3.43', 'mock': '3.14.1', 'cov': '6.1.1', 'asyncio': '1.0.0'}}\nrootdir: /Users/piyushkumarjain/insurance-ai-poc\nconfigfile: pyproject.toml\nplugins: anyio-4.9.0, json-report-1.5.0, metadata-3.1.1, langsmith-0.3.43, mock-3.14.1, cov-6.1.1, asyncio-1.0.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 0 items\n\n--------------------------------- JSON report ----------------------------------\nreport saved to: test_results_system.json\n================================ tests coverage ================================\n_______________ coverage: platform darwin, python 3.13.3-final-0 _______________\n\nName                            Stmts   Miss  Cover   Missing\n-------------------------------------------------------------\nagents/base.py                    176    176     0%   1-307\nagents/llm_client.py              141    141     0%   1-372\nagents/mcp_tools.py               207    207     0%   1-499\nui/__init__.py                      0      0   100%\nui/components/__init__.py           7      7     0%   6-13\nui/components/agent_client.py      97     97     0%   6-263\nui/components/auth.py              49     49     0%   6-86\nui/components/chat.py              79     79     0%   6-137\nui/components/config.py            21     21     0%   6-60\nui/components/monitoring.py       138    138     0%   6-231\nui/components/thinking.py         138    138     0%   6-257\nui/streamlit_app.py               106    106     0%   7-210\n-------------------------------------------------------------\nTOTAL                            1159   1159     0%\nCoverage HTML written to dir htmlcov\n============================ no tests ran in 0.12s =============================\n",
          "errors": "/Users/piyushkumarjain/insurance-ai-poc/.venv/lib/python3.13/site-packages/pytest_asyncio/plugin.py:208: PytestDeprecationWarning: The configuration option \"asyncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))\n/Users/piyushkumarjain/insurance-ai-poc/.venv/lib/python3.13/site-packages/coverage/control.py:915: CoverageWarning: No data was collected. (no-data-collected)\n  self._warn(\"No data was collected.\", slug=\"no-data-collected\")\n"
        }
      }
    },
    "ui": {
      "status": "completed",
      "results": {
        "all_ui_tests": {
          "command": "python -m pytest tests/ui/ -v --tb=short --json-report --json-report-file=test_results_ui.json",
          "success": false,
          "output": "",
          "errors": "ImportError while loading conftest '/Users/piyushkumarjain/insurance-ai-poc/tests/ui/conftest.py'.\ntests/ui/conftest.py:9: in <module>\n    from selenium import webdriver\nE   ModuleNotFoundError: No module named 'selenium'\n"
        }
      }
    }
  },
  "coverage": {
    "error": "Coverage generation failed",
    "details": "/Users/piyushkumarjain/insurance-ai-poc/.venv/lib/python3.13/site-packages/pytest_asyncio/plugin.py:208: PytestDeprecationWarning: The configuration option \"asyncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))\n/Users/piyushkumarjain/insurance-ai-poc/.venv/lib/python3.13/site-packages/coverage/control.py:915: CoverageWarning: No data was collected. (no-data-collected)\n  self._warn(\"No data was collected.\", slug=\"no-data-collected\")\n"
  },
  "metrics": {
    "total_tests": 189,
    "passed": 175,
    "failed": 9,
    "skipped": 5,
    "duration": 55.64347720146179
  }
}